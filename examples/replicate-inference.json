{
  "mcpServers": {},
  "llmModels": {
    "llama-2-70b": {
      "type": "replicate",
      "model": "meta/llama-2-70b-chat",
      "api_key": "${REPLICATE_API_TOKEN}",
      "default_params": {
        "temperature": 0.7,
        "max_tokens": 1000,
        "top_p": 0.9
      },
      "timeout": 120,
      "max_retries": 3
    },
    "mistral-7b": {
      "type": "replicate",
      "model": "mistralai/mistral-7b-instruct-v0.2",
      "api_key": "${REPLICATE_API_TOKEN}",
      "default_params": {
        "temperature": 0.5,
        "max_tokens": 500
      }
    },
    "codellama-34b": {
      "type": "replicate",
      "model": "meta/codellama-34b-instruct",
      "api_key": "${REPLICATE_API_TOKEN}",
      "default_params": {
        "temperature": 0.2,
        "max_tokens": 2000
      }
    }
  }
}
